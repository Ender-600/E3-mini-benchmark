{
  "exp_id": "inference_scaling_20251130_073752",
  "commit": "262e7199",
  "config": {
    "model": {
      "name": "llama-3.2-1b",
      "arch": "decoder",
      "pretrained": "meta-llama/Llama-3.2-1B",
      "dtype": "fp16",
      "attn_impl": "sdpa",
      "use_lora": true,
      "max_length": 4096
    },
    "bench": {
      "name": "infer_decoder_scaling",
      "arch": "decoder",
      "context_lengths": [
        128,
        256,
        512,
        1024
      ],
      "num_tokens": 50,
      "batch_size": 1,
      "num_runs": 3,
      "warmup_runs": 1
    }
  },
  "metrics": {
    "128": {
      "ttft_ms": 17.02853838602702,
      "ttft_std_ms": 0.7219939438944428,
      "throughput_tokens_per_sec": 56.53451581093476,
      "throughput_std": 0.4645146011555026,
      "e2e_latency_ms": 884.471575419108,
      "e2e_std_ms": 7.3174268062227945,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 251.6375577644201,
      "avg_power_watts": 271.0561538461538,
      "tbt_ms": 16.711100753472778,
      "tbt_std_ms": 0.14454045867855247,
      "first_token_latency_ms": 17.02853838602702,
      "latency_std_ms": 0.7219939438944428,
      "max_memory_gb": 2.3385472297668457,
      "current_memory_gb": 2.310795307159424
    },
    "256": {
      "ttft_ms": 16.910775502522785,
      "ttft_std_ms": 0.24429827472997645,
      "throughput_tokens_per_sec": 56.35220954616648,
      "throughput_std": 0.26745530893776,
      "e2e_latency_ms": 887.2952461242676,
      "e2e_std_ms": 4.196918826783893,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 251.43409839595896,
      "avg_power_watts": 270.8892307692308,
      "tbt_ms": 16.766882915886082,
      "tbt_std_ms": 0.0857067549609054,
      "first_token_latency_ms": 16.910775502522785,
      "latency_std_ms": 0.24429827472997645,
      "max_memory_gb": 2.3385472297668457,
      "current_memory_gb": 2.310795307159424
    },
    "512": {
      "ttft_ms": 16.51147206624349,
      "ttft_std_ms": 0.20011839769500236,
      "throughput_tokens_per_sec": 58.001897361677635,
      "throughput_std": 0.17114698102352835,
      "e2e_latency_ms": 862.0477676391602,
      "e2e_std_ms": 2.54256111039385,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 259.01436627134905,
      "avg_power_watts": 279.8484615384615,
      "tbt_ms": 16.25705251888353,
      "tbt_std_ms": 0.05723742699411167,
      "first_token_latency_ms": 16.51147206624349,
      "latency_std_ms": 0.20011839769500236,
      "max_memory_gb": 2.3385472297668457,
      "current_memory_gb": 2.310795307159424
    },
    "1024": {
      "ttft_ms": 17.112350463867188,
      "ttft_std_ms": 0.634025274608058,
      "throughput_tokens_per_sec": 56.42720285104792,
      "throughput_std": 0.5603230252331135,
      "e2e_latency_ms": 886.1779848734537,
      "e2e_std_ms": 8.691633421509643,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 253.91325697560188,
      "avg_power_watts": 273.4930769230769,
      "tbt_ms": 16.737302793126528,
      "tbt_std_ms": 0.17427402667453673,
      "first_token_latency_ms": 17.112350463867188,
      "latency_std_ms": 0.634025274608058,
      "max_memory_gb": 2.3385472297668457,
      "current_memory_gb": 2.310795307159424
    }
  },
  "timing": {
    "start_time": 1764509872.9486725,
    "end_time": 1764509937.757617,
    "duration_seconds": 64.80894446372986
  },
  "resources": {
    "gpu_name": "Tesla V100-SXM2-32GB",
    "max_memory_gb": 2.3385472297668457,
    "cuda_version": "12.8"
  },
  "power": {
    "avg_watt": 273.4930769230769,
    "kwh": 0.0010579719040650078,
    "duration_seconds": 13.926125288009644
  },
  "timestamp": 1764509937.7657447
}