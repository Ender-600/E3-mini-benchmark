{
  "exp_id": "inference_20251125_040224",
  "commit": "cc2e32a6",
  "config": {
    "model": {
      "name": "llama-3.2-1b",
      "arch": "decoder",
      "pretrained": "meta-llama/Llama-3.2-1B",
      "dtype": "fp16",
      "attn_impl": "sdpa",
      "use_lora": false,
      "max_length": 4096
    },
    "bench": {
      "name": "infer_decoder",
      "arch": "decoder",
      "max_length": 512,
      "num_tokens": 100,
      "batch_size": 1,
      "num_runs": 5,
      "warmup_runs": 2
    }
  },
  "metrics": {
    "ttft_ms": 19.118213653564453,
    "ttft_std_ms": 0.6033493487272809,
    "throughput_tokens_per_sec": 50.40214351071322,
    "throughput_std": 0.2737511868098759,
    "e2e_latency_ms": 1984.10005569458,
    "e2e_std_ms": 11.019009307738187,
    "total_runs": 25,
    "inference_energy_per_sample_joules": 564.8889872728832,
    "avg_power_watts": 283.33255319148924,
    "tbt_ms": 18.748241964012685,
    "tbt_std_ms": 0.11341188276368606,
    "first_token_latency_ms": 19.118213653564453,
    "latency_std_ms": 0.6033493487272809,
    "max_memory_gb": 2.3625736236572266,
    "current_memory_gb": 2.310795307159424
  },
  "timing": {
    "start_time": 1764064944.6132333,
    "end_time": 1764065024.6716359,
    "duration_seconds": 80.05840253829956
  },
  "resources": {
    "gpu_name": "Tesla V100-SXM2-32GB",
    "max_memory_gb": 2.3625736236572266,
    "cuda_version": "12.8"
  },
  "power": {
    "avg_watt": 283.33255319148924,
    "kwh": 0.003922840189395023,
    "duration_seconds": 49.84328317642212
  },
  "timestamp": 1764065024.6747758
}