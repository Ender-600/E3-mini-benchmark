{
  "exp_id": "inference_20251125_041300",
  "commit": "cc2e32a6",
  "config": {
    "model": {
      "name": "flan-t5-large",
      "arch": "encdec",
      "pretrained": "google/flan-t5-large",
      "dtype": "fp16",
      "attn_impl": "eager",
      "use_lora": false,
      "max_length": 512
    },
    "bench": {
      "name": "infer_seq2seq",
      "arch": "encdec",
      "max_length": 512,
      "num_tokens": 100,
      "batch_size": 1,
      "num_runs": 5,
      "warmup_runs": 2
    }
  },
  "metrics": {
    "ttft_ms": 69.43174362182617,
    "ttft_std_ms": 7.170923877601307,
    "encoder_latency_ms": 28.02410125732422,
    "encoder_std_ms": 2.8756635725766815,
    "throughput_tokens_per_sec": 19.96553653954406,
    "throughput_std": 2.5724954049575133,
    "e2e_latency_ms": 436.5022563934326,
    "e2e_std_ms": 455.1122716455453,
    "total_runs": 25,
    "inference_energy_per_sample_joules": 99.85776965035524,
    "avg_power_watts": 213.48545454545453,
    "tbt_ms": 44.06966792212592,
    "tbt_std_ms": 3.799248184332654,
    "first_token_latency_ms": 69.43174362182617,
    "latency_std_ms": 7.170923877601307,
    "max_memory_gb": 1.7898831367492676,
    "current_memory_gb": 1.785512924194336
  },
  "timing": {
    "start_time": 1764065580.80364,
    "end_time": 1764065626.5760176,
    "duration_seconds": 45.772377729415894
  },
  "resources": {
    "gpu_name": "Tesla V100-SXM2-32GB",
    "max_memory_gb": 1.7898831367492676,
    "cuda_version": "12.8"
  },
  "power": {
    "avg_watt": 213.48545454545453,
    "kwh": 0.0006934567336830226,
    "duration_seconds": 11.69374394416809
  },
  "timestamp": 1764065626.5801508
}