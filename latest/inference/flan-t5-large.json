{
  "exp_id": "inference_scaling_20251130_073357",
  "commit": "262e7199",
  "config": {
    "model": {
      "name": "flan-t5-large",
      "arch": "encdec",
      "pretrained": "google/flan-t5-large",
      "dtype": "fp16",
      "attn_impl": "eager",
      "use_lora": true,
      "max_length": 512
    },
    "bench": {
      "name": "infer_seq2seq_scaling",
      "arch": "encdec",
      "context_lengths": [
        128,
        256,
        512,
        1024
      ],
      "num_tokens": 50,
      "batch_size": 1,
      "num_runs": 3,
      "warmup_runs": 1
    }
  },
  "metrics": {
    "128": {
      "ttft_ms": 48.130973180135086,
      "ttft_std_ms": 0.7931446311096957,
      "encoder_latency_ms": 19.62167421976725,
      "encoder_std_ms": 0.4012332059733292,
      "throughput_tokens_per_sec": 28.41674579570388,
      "throughput_std": 2.670579184922775,
      "e2e_latency_ms": 300.2488931020101,
      "e2e_std_ms": 310.71537871217384,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 72.31005131378174,
      "avg_power_watts": 202.416,
      "tbt_ms": 30.95261991759877,
      "tbt_std_ms": 1.1290525008167482,
      "first_token_latency_ms": 48.130973180135086,
      "latency_std_ms": 0.7931446311096957,
      "max_memory_gb": 1.7898831367492676,
      "current_memory_gb": 1.785512924194336
    },
    "256": {
      "ttft_ms": 47.9422410329183,
      "ttft_std_ms": 0.8119375811457666,
      "encoder_latency_ms": 19.501225153605144,
      "encoder_std_ms": 0.40490902281855007,
      "throughput_tokens_per_sec": 28.599455853529143,
      "throughput_std": 2.5388043089103935,
      "e2e_latency_ms": 299.4197050730387,
      "e2e_std_ms": 311.23409983259313,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 72.42928490613302,
      "avg_power_watts": 202.81400000000002,
      "tbt_ms": 30.586850495986,
      "tbt_std_ms": 0.5350620918929412,
      "first_token_latency_ms": 47.9422410329183,
      "latency_std_ms": 0.8119375811457666,
      "max_memory_gb": 1.7898831367492676,
      "current_memory_gb": 1.785512924194336
    },
    "512": {
      "ttft_ms": 48.2213020324707,
      "ttft_std_ms": 0.8370264561978611,
      "encoder_latency_ms": 19.733778635660805,
      "encoder_std_ms": 0.5246292570975868,
      "throughput_tokens_per_sec": 28.65622722296188,
      "throughput_std": 2.5942189119073533,
      "e2e_latency_ms": 298.3919143676758,
      "e2e_std_ms": 309.9390204743372,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 72.192546706295,
      "avg_power_watts": 202.398,
      "tbt_ms": 30.470479859246147,
      "tbt_std_ms": 0.49359085664924396,
      "first_token_latency_ms": 48.2213020324707,
      "latency_std_ms": 0.8370264561978611,
      "max_memory_gb": 1.7898831367492676,
      "current_memory_gb": 1.785512924194336
    },
    "1024": {
      "ttft_ms": 48.49824905395508,
      "ttft_std_ms": 1.4606449285605907,
      "encoder_latency_ms": 19.882615407307945,
      "encoder_std_ms": 0.9319881519933624,
      "throughput_tokens_per_sec": 28.67365673380145,
      "throughput_std": 2.6674359416172355,
      "e2e_latency_ms": 297.8013197580973,
      "e2e_std_ms": 308.88333799980995,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 71.9151547706604,
      "avg_power_watts": 202.416,
      "tbt_ms": 30.296633861683034,
      "tbt_std_ms": 0.4060150109490184,
      "first_token_latency_ms": 48.49824905395508,
      "latency_std_ms": 1.4606449285605907,
      "max_memory_gb": 1.7898831367492676,
      "current_memory_gb": 1.785512924194336
    }
  },
  "timing": {
    "start_time": 1764509637.0489154,
    "end_time": 1764509662.8193321,
    "duration_seconds": 25.770416736602783
  },
  "resources": {
    "gpu_name": "Tesla V100-SXM2-32GB",
    "max_memory_gb": 1.7898831367492676,
    "cuda_version": "12.8"
  },
  "power": {
    "avg_watt": 202.416,
    "kwh": 0.00029964647821108497,
    "duration_seconds": 5.329259157180786
  },
  "timestamp": 1764509662.8267472
}