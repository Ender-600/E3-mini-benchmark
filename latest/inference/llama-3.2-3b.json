{
  "exp_id": "inference_scaling_20251130_073902",
  "commit": "262e7199",
  "config": {
    "model": {
      "name": "llama-3.2-3b",
      "arch": "decoder",
      "pretrained": "meta-llama/Llama-3.2-3B",
      "dtype": "fp16",
      "attn_impl": "sdpa",
      "use_lora": true,
      "max_length": 4096
    },
    "bench": {
      "name": "infer_decoder_scaling",
      "arch": "decoder",
      "context_lengths": [
        128,
        256,
        512,
        1024
      ],
      "num_tokens": 50,
      "batch_size": 1,
      "num_runs": 3,
      "warmup_runs": 1
    }
  },
  "metrics": {
    "128": {
      "ttft_ms": 28.54021390279134,
      "ttft_std_ms": 0.6944558428805337,
      "throughput_tokens_per_sec": 33.57625193498565,
      "throughput_std": 0.3050325291794094,
      "e2e_latency_ms": 1489.2643133799236,
      "e2e_std_ms": 13.748097725299413,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 468.9942984142303,
      "avg_power_watts": 313.08,
      "tbt_ms": 28.1070005326044,
      "tbt_std_ms": 0.2803356062704519,
      "first_token_latency_ms": 28.54021390279134,
      "latency_std_ms": 0.6944558428805337,
      "max_memory_gb": 6.020498752593994,
      "current_memory_gb": 5.992636203765869
    },
    "256": {
      "ttft_ms": 28.21340560913086,
      "ttft_std_ms": 0.40603085816613466,
      "throughput_tokens_per_sec": 33.76105277445139,
      "throughput_std": 0.11299670429521394,
      "e2e_latency_ms": 1481.011946996053,
      "e2e_std_ms": 4.954350019777371,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 475.4045930720738,
      "avg_power_watts": 317.75142857142856,
      "tbt_ms": 27.939072433783085,
      "tbt_std_ms": 0.10346658468634,
      "first_token_latency_ms": 28.21340560913086,
      "latency_std_ms": 0.40603085816613466,
      "max_memory_gb": 6.020498752593994,
      "current_memory_gb": 5.992636203765869
    },
    "512": {
      "ttft_ms": 28.499301274617515,
      "ttft_std_ms": 0.6044081375337047,
      "throughput_tokens_per_sec": 33.638187141877346,
      "throughput_std": 0.20999005377248667,
      "e2e_latency_ms": 1486.4606698354087,
      "e2e_std_ms": 9.399808263929067,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 483.35660491121365,
      "avg_power_watts": 321.8257142857142,
      "tbt_ms": 28.04460233571578,
      "tbt_std_ms": 0.18156905342007706,
      "first_token_latency_ms": 28.499301274617515,
      "latency_std_ms": 0.6044081375337047,
      "max_memory_gb": 6.020498752593994,
      "current_memory_gb": 5.992636203765869
    },
    "1024": {
      "ttft_ms": 32.18183517456055,
      "ttft_std_ms": 4.754001285883945,
      "throughput_tokens_per_sec": 30.40972989027656,
      "throughput_std": 3.9422764856599506,
      "e2e_latency_ms": 1671.7867851257324,
      "e2e_std_ms": 227.9465375893172,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 543.596480697751,
      "avg_power_watts": 317.75249999999994,
      "tbt_ms": 31.779781328577574,
      "tbt_std_ms": 4.590246138629667,
      "first_token_latency_ms": 32.18183517456055,
      "latency_std_ms": 4.754001285883945,
      "max_memory_gb": 6.020498752593994,
      "current_memory_gb": 5.992636203765869
    }
  },
  "timing": {
    "start_time": 1764509942.6865196,
    "end_time": 1764510090.282727,
    "duration_seconds": 147.5962073802948
  },
  "resources": {
    "gpu_name": "Tesla V100-SXM2-32GB",
    "max_memory_gb": 6.020498752593994,
    "cuda_version": "12.8"
  },
  "power": {
    "avg_watt": 317.75249999999994,
    "kwh": 0.002264985336240629,
    "duration_seconds": 25.66131567955017
  },
  "timestamp": 1764510090.2899952
}