{
  "exp_id": "inference_scaling_20251113_191247",
  "commit": "c9d44d13",
  "config": {
    "model": {
      "name": "bert-base-uncased",
      "arch": "encoder",
      "pretrained": "bert-base-uncased",
      "dtype": "fp16",
      "attn_impl": "eager",
      "use_lora": true,
      "max_length": 256
    },
    "bench": {
      "name": "infer_encoder_scaling",
      "arch": "encoder",
      "context_lengths": [
        128,
        256,
        512,
        1024
      ],
      "batch_size": 1,
      "num_runs": 3,
      "warmup_runs": 1
    }
  },
  "metrics": {
    "128": {
      "forward_pass_latency_ms": 7.9786618550618496,
      "latency_std_ms": 0.27448103898409915,
      "total_runs": 15,
      "max_memory_gb": 0.22004413604736328,
      "current_memory_gb": 0.21984577178955078
    },
    "256": {
      "forward_pass_latency_ms": 7.841380437215169,
      "latency_std_ms": 0.01760516171044652,
      "total_runs": 15,
      "max_memory_gb": 0.22004413604736328,
      "current_memory_gb": 0.21984577178955078
    },
    "512": {
      "forward_pass_latency_ms": 7.86283810933431,
      "latency_std_ms": 0.070518768376763,
      "total_runs": 15,
      "max_memory_gb": 0.22004413604736328,
      "current_memory_gb": 0.21984577178955078
    },
    "1024": {
      "forward_pass_latency_ms": 7.924064000447592,
      "latency_std_ms": 0.23334909634645692,
      "total_runs": 15,
      "max_memory_gb": 0.22004413604736328,
      "current_memory_gb": 0.21984577178955078
    }
  },
  "timing": {
    "start_time": 1763082767.026147,
    "end_time": 1763082770.8941941,
    "duration_seconds": 3.8680472373962402
  },
  "resources": {
    "gpu_name": "Tesla V100-SXM2-32GB",
    "max_memory_gb": 0.22004413604736328,
    "cuda_version": "12.8"
  },
  "power": {
    "avg_watt": null,
    "kwh": null,
    "duration_seconds": 4.840980052947998
  },
  "timestamp": 1763082771.871126
}