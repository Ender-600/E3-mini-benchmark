{
  "exp_id": "inference_20251101_213320",
  "commit": "84a9f6c7",
  "config": {
    "model": {
      "name": "t5-base",
      "arch": "encdec",
      "pretrained": "t5-base",
      "dtype": "fp16",
      "attn_impl": "eager",
      "use_lora": true,
      "max_length": 256
    },
    "bench": {
      "name": "infer_seq2seq",
      "arch": "encdec",
      "max_length": 512,
      "num_tokens": 100,
      "batch_size": 1,
      "num_runs": 5,
      "warmup_runs": 2
    }
  },
  "metrics": {
    "first_token_latency_ms": 26.06439900693131,
    "latency_std_ms": 12.00133938063686,
    "throughput_tokens_per_sec": 45.26479873844561,
    "throughput_std": 15.993355232365667,
    "total_runs": 25,
    "max_memory_gb": 0.5519113540649414,
    "current_memory_gb": 0.5500173568725586
  },
  "timing": {
    "start_time": 1762050800.1949124,
    "end_time": 1762050814.4103372,
    "duration_seconds": 14.21542477607727
  },
  "resources": {
    "gpu_name": "Tesla V100-SXM2-32GB",
    "max_memory_gb": 0.5519113540649414,
    "cuda_version": "12.8"
  },
  "power": {
    "avg_watt": 223.22999999999996,
    "kwh": 0.0006200833333333332
  },
  "timestamp": 1762050814.5641823
}