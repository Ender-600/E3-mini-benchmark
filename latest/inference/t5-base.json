{
  "exp_id": "inference_scaling_20251113_191208",
  "commit": "c9d44d13",
  "config": {
    "model": {
      "name": "t5-base",
      "arch": "encdec",
      "pretrained": "t5-base",
      "dtype": "fp16",
      "attn_impl": "eager",
      "use_lora": true,
      "max_length": 256
    },
    "bench": {
      "name": "infer_seq2seq_scaling",
      "arch": "encdec",
      "context_lengths": [
        128,
        256,
        512,
        1024
      ],
      "num_tokens": 50,
      "batch_size": 1,
      "num_runs": 3,
      "warmup_runs": 1
    }
  },
  "metrics": {
    "128": {
      "ttft_ms": 33.509159088134766,
      "ttft_std_ms": 0.35630647088192147,
      "encoder_latency_ms": 13.02010218302409,
      "encoder_std_ms": 0.16745570908992516,
      "throughput_tokens_per_sec": 42.19971642528037,
      "throughput_std": 4.044215266276471,
      "e2e_latency_ms": 401.0484218597412,
      "e2e_std_ms": 323.4987013115522,
      "total_runs": 15,
      "tbt_ms": 21.558352353406228,
      "tbt_std_ms": 0.664727806530307,
      "first_token_latency_ms": 33.509159088134766,
      "latency_std_ms": 0.35630647088192147,
      "max_memory_gb": 0.5552840232849121,
      "current_memory_gb": 0.5500173568725586
    },
    "256": {
      "ttft_ms": 33.50566228230794,
      "ttft_std_ms": 0.29917336283607493,
      "encoder_latency_ms": 13.064908981323242,
      "encoder_std_ms": 0.21628288474827811,
      "throughput_tokens_per_sec": 42.44080792643694,
      "throughput_std": 4.016665855308506,
      "e2e_latency_ms": 398.97637367248535,
      "e2e_std_ms": 321.91596922587553,
      "total_runs": 15,
      "tbt_ms": 21.371520902116792,
      "tbt_std_ms": 0.18999030608614753,
      "first_token_latency_ms": 33.50566228230794,
      "latency_std_ms": 0.29917336283607493,
      "max_memory_gb": 0.5552840232849121,
      "current_memory_gb": 0.5500173568725586
    },
    "512": {
      "ttft_ms": 33.47695668538411,
      "ttft_std_ms": 0.29779262976758536,
      "encoder_latency_ms": 13.10280164082845,
      "encoder_std_ms": 0.26570861490585773,
      "throughput_tokens_per_sec": 42.456388330321026,
      "throughput_std": 3.987317366575364,
      "e2e_latency_ms": 399.2228666941325,
      "e2e_std_ms": 322.5068225389782,
      "total_runs": 15,
      "tbt_ms": 21.345195667176704,
      "tbt_std_ms": 0.14525809034196416,
      "first_token_latency_ms": 33.47695668538411,
      "latency_std_ms": 0.29779262976758536,
      "max_memory_gb": 0.5552840232849121,
      "current_memory_gb": 0.5500173568725586
    },
    "1024": {
      "ttft_ms": 33.38692982991536,
      "ttft_std_ms": 0.24364326556105334,
      "encoder_latency_ms": 12.989282608032227,
      "encoder_std_ms": 0.14971759314444355,
      "throughput_tokens_per_sec": 42.529732598976395,
      "throughput_std": 3.9549247455755743,
      "e2e_latency_ms": 398.67041905721027,
      "e2e_std_ms": 321.93145083784134,
      "total_runs": 15,
      "tbt_ms": 21.321321468727263,
      "tbt_std_ms": 0.13278288191271967,
      "first_token_latency_ms": 33.38692982991536,
      "latency_std_ms": 0.24364326556105334,
      "max_memory_gb": 0.5552840232849121,
      "current_memory_gb": 0.5500173568725586
    }
  },
  "timing": {
    "start_time": 1763082728.3560667,
    "end_time": 1763082759.8510785,
    "duration_seconds": 31.495011806488037
  },
  "resources": {
    "gpu_name": "Tesla V100-SXM2-32GB",
    "max_memory_gb": 0.5552840232849121,
    "cuda_version": "12.8"
  },
  "power": {
    "avg_watt": null,
    "kwh": null,
    "duration_seconds": 32.318583488464355
  },
  "timestamp": 1763082760.6764634
}