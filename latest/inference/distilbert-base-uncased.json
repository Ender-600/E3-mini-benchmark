{
  "exp_id": "inference_20251125_015346",
  "commit": "cc2e32a6",
  "config": {
    "model": {
      "name": "distilbert-base-uncased",
      "arch": "encoder",
      "pretrained": "distilbert-base-uncased",
      "dtype": "fp16",
      "attn_impl": "eager",
      "use_lora": false,
      "max_length": 512
    },
    "bench": {
      "name": "infer_encoder",
      "arch": "encoder",
      "max_length": 512,
      "batch_size": 1,
      "num_runs": 5,
      "warmup_runs": 2
    }
  },
  "metrics": {
    "forward_pass_latency_ms": 4.968605041503906,
    "latency_std_ms": 0.7407989508668761,
    "total_runs": 25,
    "inference_energy_per_sample_joules": 9.542775553131104,
    "avg_power_watts": 224.72,
    "max_memory_gb": 0.13739871978759766,
    "current_memory_gb": 0.1372079849243164
  },
  "timing": {
    "start_time": 1764057226.325922,
    "end_time": 1764057235.2730603,
    "duration_seconds": 8.94713830947876
  },
  "resources": {
    "gpu_name": "Tesla V100-SXM2-32GB",
    "max_memory_gb": 0.13739871978759766,
    "cuda_version": "12.8"
  },
  "power": {
    "avg_watt": 224.72,
    "kwh": 6.626927467452156e-05,
    "duration_seconds": 1.0616295337677002
  },
  "timestamp": 1764057235.276458
}