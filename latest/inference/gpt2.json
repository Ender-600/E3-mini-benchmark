{
  "exp_id": "inference_20251127_045047",
  "commit": "820050ad",
  "config": {
    "model": {
      "name": "gpt2",
      "arch": "decoder",
      "pretrained": "gpt2",
      "dtype": "fp16",
      "attn_impl": "eager",
      "use_lora": true,
      "max_length": 256
    },
    "bench": {
      "name": "infer_decoder",
      "arch": "decoder",
      "max_length": 512,
      "num_tokens": 100,
      "batch_size": 1,
      "num_runs": 5,
      "warmup_runs": 2
    }
  },
  "metrics": {
    "ttft_ms": 10.994873046875,
    "ttft_std_ms": 1.2221389633616544,
    "throughput_tokens_per_sec": 87.92320952479653,
    "throughput_std": 9.335589101316579,
    "e2e_latency_ms": 1150.0194358825684,
    "e2e_std_ms": 124.58071768698744,
    "total_runs": 25,
    "inference_energy_per_sample_joules": 235.03281542857138,
    "avg_power_watts": 203.52481481481485,
    "tbt_ms": 11.047612681533352,
    "tbt_std_ms": 1.2529181078919542,
    "first_token_latency_ms": 10.994873046875,
    "latency_std_ms": 1.2221389633616544,
    "max_memory_gb": 0.2785067558288574,
    "current_memory_gb": 0.2584104537963867
  },
  "timing": {
    "start_time": 1764240647.5192385,
    "end_time": 1764240680.3195074,
    "duration_seconds": 32.80026888847351
  },
  "resources": {
    "gpu_name": "Tesla V100-SXM2-32GB",
    "max_memory_gb": 0.2785067558288574,
    "cuda_version": "12.8"
  },
  "power": {
    "avg_watt": 203.52481481481485,
    "kwh": 0.0016321723293650794,
    "duration_seconds": 28.87028980255127
  },
  "timestamp": 1764240680.3267412
}