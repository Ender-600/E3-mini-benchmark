{
  "exp_id": "inference_scaling_20251113_191111",
  "commit": "c9d44d13",
  "config": {
    "model": {
      "name": "gpt2",
      "arch": "decoder",
      "pretrained": "gpt2",
      "dtype": "fp16",
      "attn_impl": "eager",
      "use_lora": true,
      "max_length": 256
    },
    "bench": {
      "name": "infer_decoder_scaling",
      "arch": "decoder",
      "context_lengths": [
        128,
        256,
        512,
        1024
      ],
      "num_tokens": 50,
      "batch_size": 1,
      "num_runs": 3,
      "warmup_runs": 1
    }
  },
  "metrics": {
    "128": {
      "ttft_ms": 14.09597396850586,
      "ttft_std_ms": 0.2175047180936164,
      "throughput_tokens_per_sec": 67.8888640655121,
      "throughput_std": 0.7354115677761168,
      "e2e_latency_ms": 736.5811824798584,
      "e2e_std_ms": 8.246195872643833,
      "total_runs": 15,
      "tbt_ms": 14.206619327571117,
      "tbt_std_ms": 0.1701611056016328,
      "first_token_latency_ms": 14.09597396850586,
      "latency_std_ms": 0.2175047180936164,
      "max_memory_gb": 0.269073486328125,
      "current_memory_gb": 0.2584104537963867
    },
    "256": {
      "ttft_ms": 14.133437474568685,
      "ttft_std_ms": 0.10668248455782325,
      "throughput_tokens_per_sec": 67.21055577160237,
      "throughput_std": 3.304106018477333,
      "e2e_latency_ms": 745.9447383880615,
      "e2e_std_ms": 43.895008027107075,
      "total_runs": 15,
      "tbt_ms": 14.396128362538862,
      "tbt_std_ms": 0.8961415957699094,
      "first_token_latency_ms": 14.133437474568685,
      "latency_std_ms": 0.10668248455782325,
      "max_memory_gb": 0.269073486328125,
      "current_memory_gb": 0.2584104537963867
    },
    "512": {
      "ttft_ms": 11.351760228474934,
      "ttft_std_ms": 0.06177982703505897,
      "throughput_tokens_per_sec": 84.42474381246024,
      "throughput_std": 0.20891733357146866,
      "e2e_latency_ms": 592.2468185424805,
      "e2e_std_ms": 1.4663875549356828,
      "total_runs": 15,
      "tbt_ms": 11.306486648767173,
      "tbt_std_ms": 0.02998982442309929,
      "first_token_latency_ms": 11.351760228474934,
      "latency_std_ms": 0.06177982703505897,
      "max_memory_gb": 0.269073486328125,
      "current_memory_gb": 0.2584104537963867
    },
    "1024": {
      "ttft_ms": 11.381101608276367,
      "ttft_std_ms": 0.061937208479412906,
      "throughput_tokens_per_sec": 84.37018240361779,
      "throughput_std": 0.13249652148967553,
      "e2e_latency_ms": 592.6277955373129,
      "e2e_std_ms": 0.9316187373692083,
      "total_runs": 15,
      "tbt_ms": 11.313905521314972,
      "tbt_std_ms": 0.018863061044049063,
      "first_token_latency_ms": 11.381101608276367,
      "latency_std_ms": 0.061937208479412906,
      "max_memory_gb": 0.269073486328125,
      "current_memory_gb": 0.2584104537963867
    }
  },
  "timing": {
    "start_time": 1763082671.339839,
    "end_time": 1763082720.8591058,
    "duration_seconds": 49.519266843795776
  },
  "resources": {
    "gpu_name": "Tesla V100-SXM2-32GB",
    "max_memory_gb": 0.269073486328125,
    "cuda_version": "12.8"
  },
  "power": {
    "avg_watt": null,
    "kwh": null,
    "duration_seconds": 50.47904634475708
  },
  "timestamp": 1763082721.822966
}