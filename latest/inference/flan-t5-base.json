{
  "exp_id": "inference_scaling_20251130_073335",
  "commit": "262e7199",
  "config": {
    "model": {
      "name": "flan-t5-base",
      "arch": "encdec",
      "pretrained": "google/flan-t5-base",
      "dtype": "fp16",
      "attn_impl": "eager",
      "use_lora": true,
      "max_length": 512
    },
    "bench": {
      "name": "infer_seq2seq_scaling",
      "arch": "encdec",
      "context_lengths": [
        128,
        256,
        512,
        1024
      ],
      "num_tokens": 50,
      "batch_size": 1,
      "num_runs": 3,
      "warmup_runs": 1
    }
  },
  "metrics": {
    "128": {
      "ttft_ms": 33.292531967163086,
      "ttft_std_ms": 1.2646884224911663,
      "encoder_latency_ms": 13.543844223022461,
      "encoder_std_ms": 0.911871027706646,
      "throughput_tokens_per_sec": 44.06360231654535,
      "throughput_std": 2.167663706551031,
      "e2e_latency_ms": 192.51580238342285,
      "e2e_std_ms": 91.66540971382598,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 42.11269696638319,
      "avg_power_watts": 196.21333333333334,
      "tbt_ms": 20.812853951474803,
      "tbt_std_ms": 0.9768063467416706,
      "first_token_latency_ms": 33.292531967163086,
      "latency_std_ms": 1.2646884224911663,
      "max_memory_gb": 0.5493435859680176,
      "current_memory_gb": 0.5475759506225586
    },
    "256": {
      "ttft_ms": 32.709407806396484,
      "ttft_std_ms": 0.7842608234864017,
      "encoder_latency_ms": 13.293600082397461,
      "encoder_std_ms": 0.44029705674855707,
      "throughput_tokens_per_sec": 44.76730866198395,
      "throughput_std": 1.7163087460392317,
      "e2e_latency_ms": 189.2883618672689,
      "e2e_std_ms": 90.18799726960923,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 41.86123624356588,
      "avg_power_watts": 196.03666666666666,
      "tbt_ms": 20.476613897953886,
      "tbt_std_ms": 0.45820071071895996,
      "first_token_latency_ms": 32.709407806396484,
      "latency_std_ms": 0.7842608234864017,
      "max_memory_gb": 0.5493435859680176,
      "current_memory_gb": 0.5475759506225586
    },
    "512": {
      "ttft_ms": 33.06023279825846,
      "ttft_std_ms": 0.8168588233612338,
      "encoder_latency_ms": 13.448381423950195,
      "encoder_std_ms": 0.49031356360506845,
      "throughput_tokens_per_sec": 44.677924859397656,
      "throughput_std": 1.7100730202019463,
      "e2e_latency_ms": 189.42818641662598,
      "e2e_std_ms": 89.83926006296747,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 42.15001571655273,
      "avg_power_watts": 196.35,
      "tbt_ms": 20.477165047396486,
      "tbt_std_ms": 0.26766408312864004,
      "first_token_latency_ms": 33.06023279825846,
      "latency_std_ms": 0.8168588233612338,
      "max_memory_gb": 0.5493435859680176,
      "current_memory_gb": 0.5475759506225586
    },
    "1024": {
      "ttft_ms": 33.35614204406738,
      "ttft_std_ms": 1.1706578032208574,
      "encoder_latency_ms": 13.573487599690756,
      "encoder_std_ms": 0.5613451374689393,
      "throughput_tokens_per_sec": 44.30764785027999,
      "throughput_std": 1.7664102430628568,
      "e2e_latency_ms": 191.26726786295572,
      "e2e_std_ms": 90.95551166591044,
      "total_runs": 15,
      "inference_energy_per_sample_joules": 42.42693348386552,
      "avg_power_watts": 196.51333333333332,
      "tbt_ms": 20.636124304706744,
      "tbt_std_ms": 0.5417790521892406,
      "first_token_latency_ms": 33.35614204406738,
      "latency_std_ms": 1.1706578032208574,
      "max_memory_gb": 0.5493435859680176,
      "current_memory_gb": 0.5475759506225586
    }
  },
  "timing": {
    "start_time": 1764509615.6367872,
    "end_time": 1764509632.180084,
    "duration_seconds": 16.543296813964844
  },
  "resources": {
    "gpu_name": "Tesla V100-SXM2-32GB",
    "max_memory_gb": 0.5493435859680176,
    "cuda_version": "12.8"
  },
  "power": {
    "avg_watt": 196.51333333333332,
    "kwh": 0.00017677888951610636,
    "duration_seconds": 3.2384774684906006
  },
  "timestamp": 1764509632.1879191
}