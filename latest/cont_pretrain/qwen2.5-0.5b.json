{
  "exp_id": "cont_pretrain_20251129_161741",
  "commit": "067ece39",
  "config": {
    "model": {
      "name": "qwen2.5-0.5b",
      "arch": "decoder",
      "pretrained": "Qwen/Qwen2.5-0.5B",
      "dtype": "fp16",
      "attn_impl": "sdpa",
      "use_lora": true,
      "max_length": 4096
    },
    "train": {
      "name": "lora",
      "fp16": false,
      "grad_checkpointing": false,
      "per_device_train_batch_size": 16,
      "per_device_eval_batch_size": 32,
      "gradient_accumulation_steps": 2,
      "num_train_epochs": 5,
      "learning_rate": 5e-05,
      "weight_decay": 0.01,
      "warmup_ratio": 0.1,
      "max_length": 256,
      "seed": [
        42
      ],
      "save_strategy": "epoch",
      "eval_strategy": "epoch",
      "logging_steps": 10,
      "save_total_limit": 2,
      "lora_r": 16,
      "lora_alpha": 32,
      "lora_dropout": 0.05
    },
    "dataset": "wikitext",
    "target_loss": 2.0,
    "token_budget": 1000000
  },
  "metrics": {
    "final_eval_loss": 2.8833906650543213,
    "best_eval_loss": 2.8833906650543213,
    "epochs_trained": 5,
    "total_tokens": 661760,
    "token_budget": 1000000,
    "duration_seconds": 315.315039396286,
    "tokens_per_second": 2098.72640793484,
    "target_reached": false,
    "lora_params": {
      "trainable_params": 2162688,
      "total_params": 496195456,
      "trainable_percentage": 0.43585405183557346
    }
  },
  "timing": {
    "start_time": 1764454661.9169908,
    "end_time": 1764454977.2360082,
    "duration_seconds": 315.3190174102783
  },
  "resources": {
    "gpu_name": "Tesla V100-SXM2-32GB",
    "max_memory_gb": 26.03627920150757,
    "cuda_version": "12.8"
  },
  "power": {
    "avg_watt": null,
    "kwh": null,
    "duration_seconds": 315.5656564235687
  },
  "timestamp": 1764454977.4885798
}