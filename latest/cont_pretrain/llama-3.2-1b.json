{
  "exp_id": "cont_pretrain_20251129_162331",
  "commit": "067ece39",
  "config": {
    "model": {
      "name": "llama-3.2-1b",
      "arch": "decoder",
      "pretrained": "meta-llama/Llama-3.2-1B",
      "dtype": "fp16",
      "attn_impl": "sdpa",
      "use_lora": true,
      "max_length": 4096
    },
    "train": {
      "name": "lora",
      "fp16": false,
      "grad_checkpointing": false,
      "per_device_train_batch_size": 16,
      "per_device_eval_batch_size": 32,
      "gradient_accumulation_steps": 2,
      "num_train_epochs": 5,
      "learning_rate": 5e-05,
      "weight_decay": 0.01,
      "warmup_ratio": 0.1,
      "max_length": 256,
      "seed": [
        42
      ],
      "save_strategy": "epoch",
      "eval_strategy": "epoch",
      "logging_steps": 10,
      "save_total_limit": 2,
      "lora_r": 16,
      "lora_alpha": 32,
      "lora_dropout": 0.05
    },
    "dataset": "wikitext",
    "target_loss": 2.0,
    "token_budget": 1000000
  },
  "metrics": {
    "final_eval_loss": 2.5344302654266357,
    "best_eval_loss": 2.5344302654266357,
    "epochs_trained": 4,
    "total_tokens": 819200,
    "token_budget": 1000000,
    "duration_seconds": 624.7132406234741,
    "tokens_per_second": 1311.3216540479034,
    "target_reached": false,
    "lora_params": {
      "trainable_params": 3407872,
      "total_params": 1239222272,
      "trainable_percentage": 0.2750008676409586
    }
  },
  "timing": {
    "start_time": 1764455011.8104343,
    "end_time": 1764455636.5262487,
    "duration_seconds": 624.7158143520355
  },
  "resources": {
    "gpu_name": "Tesla V100-SXM2-32GB",
    "max_memory_gb": 29.414592742919922,
    "cuda_version": "12.8"
  },
  "power": {
    "avg_watt": null,
    "kwh": null,
    "duration_seconds": 624.7914135456085
  },
  "timestamp": 1764455636.6075509
}